# ğŸ« LLM-Based Ticket Reply Evaluator
**Rauda AI â€” Take-Home Assignment**

EvalÃºa respuestas de soporte al cliente usando un LLM, puntuando cada reply en
**contenido** (relevancia, exactitud, completitud) y **formato** (claridad, estructura,
gramÃ¡tica) en una escala del 1 al 5 con explicaciÃ³n textual.

> **Nota de implementaciÃ³n:** El assignment original especifica OpenAI GPT-4o.
> Esta soluciÃ³n usa **Llama 3.3 70B** vÃ­a **Groq API**. Cambiar a GPT-4o en producciÃ³n
> requiere modificar Ãºnicamente el cliente y el nombre del modelo.

---

## ğŸ—ï¸ Estructura del proyecto

```
rauda_ai_test/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ tickets.csv
â”‚   â””â”€â”€ tickets_evaluated.csv
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ ticket_evaluator_groq.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_evaluator.py
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Setup

### 1. Clona el repositorio

```bash
git clone <repo-url>
cd rauda_ai_test
```

### 2. Crea y activa el entorno virtual

```bash
python -m venv venv

# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate
```

### 3. Instala las dependencias

```bash
pip install -r requirements.txt
```

### 4. Registra el entorno en Jupyter para poder usarlo como kernel

```bash
pip install ipykernel
python -m ipykernel install --user --name=venv --display-name "Python (venv)"
```

### 5. Consigue tu API Key gratuita de Groq

1. Ve a [console.groq.com](https://console.groq.com) y regÃ­strate con Google o email
2. Ve a **"API Keys"** â†’ **"Create API Key"**
3. No necesitas tarjeta de crÃ©dito

### 6. Configura las credenciales

Crea un archivo `.env` en la raÃ­z del proyecto:

```
GROQ_API_KEY=gsk_...tu-clave-aqui...
```

> âš ï¸ **Seguridad:** El archivo `.env` estÃ¡ en `.gitignore` y **nunca** debe subirse
> a GitHub. Si se expone pÃºblicamente, cualquiera puede usar tu clave y agotar tu cuota.
> Por eso usamos `python-dotenv` para cargar credenciales desde el entorno local,
> nunca hardcodeadas en el cÃ³digo.

---

## â–¶ï¸ EjecuciÃ³n

### OpciÃ³n A â€” Jupyter Notebook (recomendado)

```bash
jupyter notebook notebooks/ticket_evaluator_groq.ipynb
```

Selecciona el kernel **"Python (venv)"** y ejecuta las celdas en orden.
El resultado se guarda en `tickets_evaluated.csv`.

### OpciÃ³n B â€” Script Python

```bash
python src/main.py
```

---

## ğŸ§ª Tests

```bash
pytest tests/test_evaluator.py -v
```

Los tests cubren las funciones core **sin llamadas reales a la API** (usan `unittest.mock`):
- Lectura y validaciÃ³n del CSV de entrada
- ConstrucciÃ³n del User Prompt con caracteres especiales y unicode
- ValidaciÃ³n del schema de respuesta del LLM (campos, tipos, rango de scores)
- Escritura y estructura del CSV de salida

---

## ğŸ“¦ Dependencias

| LibrerÃ­a | Uso |
|---|---|
| `groq` | Cliente oficial Groq API |
| `pandas` | Lectura y escritura de CSV |
| `python-dotenv` | Carga segura de variables de entorno desde `.env` |
| `tenacity` | Retries automÃ¡ticos con backoff exponencial |
| `pytest` | Suite de tests unitarios |
| `jupyter` | Entorno de ejecuciÃ³n del notebook |

---

## ğŸ›ï¸ Decisiones de arquitectura

**Â¿Por quÃ© Groq + Llama 3.3 70B?**
Groq ofrece tier gratuito sin tarjeta, con API compatible con el estÃ¡ndar OpenAI.
Migrar a GPT-4o requiere cambiar Ãºnicamente el cliente y el nombre del modelo.

**Â¿Por quÃ© JSON mode?**
`response_format={"type": "json_object"}` garantiza que el modelo devuelva siempre
JSON vÃ¡lido. Elimina la necesidad de regex frÃ¡giles para parsear texto libre.

**Â¿Por quÃ© temperatura 0.1?**
Las evaluaciones deben ser reproducibles. Temperatura baja genera respuestas
consistentes â€” el mismo ticket evaluado dos veces debe dar scores similares.

**Â¿Por quÃ© retries con backoff exponencial?**
`tenacity` reintenta ante errores 429/503 esperando 2s â†’ 4s â†’ 8s â†’ 16s,
respetando los lÃ­mites del proveedor sin saturarlo.

**Â¿Por quÃ© fail-safe por fila?**
Si una fila falla permanentemente, se registra el error y el pipeline continÃºa.
Se procesan 499/500 tickets correctamente aunque uno falle.

---

## ğŸš€ Escalabilidad a 1 millÃ³n de tickets

### 1. Procesamiento concurrente con asyncio
La versiÃ³n actual es secuencial. Con `asyncio` y `asyncio.Semaphore(50)` se
lanzarÃ­an 50 llamadas concurrentes, reduciendo el tiempo de dÃ­as a horas.

### 2. Arquitectura de cola con AWS SQS + Lambda
- **S3** recibe el CSV â†’ **Lambda** publica cada fila en **SQS**
- MÃºltiples **Lambda workers** procesan en paralelo â†’ resultados en **DynamoDB**
- Ventajas: escalado automÃ¡tico, Dead Letter Queue para fallos, pay-per-execution

### 3. Control de costes y observabilidad
- CachÃ© semÃ¡ntica (Redis) para tickets similares ya evaluados
- Modelo tiered: barato para el grueso, premium solo para scores 2-3 â†’ ahorro ~80%
- Alertas de presupuesto + logging de tokens consumidos por llamada
